# 数据隐私HW2
**罗浩铭 PB21030838**

## 1 Laplace mechanism

### (a)
此处对相邻数据集$D$和$D'$的定义为$D$和$D'$只有一个元素不同。

计算全局敏感度如下：
因为$x_i$的取值最小为1，最大为10，所以$|x_i-x_i'|$最大为9。由于$f=\frac{1}{6} \sum_{i=1}^{6} x_i$，所以全局敏感度为
$$
\Delta f=\max_{x,y \in D, \left \| x-y \right \|_1=1 } \left \| f(x)-f(y) \right \|_1=\frac{3}{2}
$$

计算局部敏感度为：
因为$x=\{3,5,4,5,6,7\}$，$x_i$的取值最小为1，最大为10，则修改其中一维能使得$f(x)$产生最大变化的是将$x_1$从3改为10，也即所以$|x_i-x_i'|$最大为7。所以局部敏感度为
$$
\Delta f=\max_{y \in D, \left \| x-y \right \|_1=1 } \left \| f(x)-f(y) \right \|_1=\frac{7}{6}
$$


### (b)
本小题数据库仍然为6维。记数据取值范围为$M = \{ 1,2,3,4,5,6 \}$

#### (1)
因为$q_1(x)=\sum_{i=1}^{6} x_i$
$$
\Delta q_1=\max_{x,y \in D, \left \| x-y \right \|_1=1 } \left \| q_1(x)-q_1(y) \right \|_1 \\
=\max_{p,q \in M} |p-q| =5
$$
则设计拉普拉斯机制函数如下：
$$
M_{L1}(x)=q_1(x)+Lap\left ( \frac{\Delta q_1}{\epsilon} \right ) \\
= q_1(x)+Lap\left ( 50 \right )
$$

#### (2)
因为$q_2(x)=\max_{i \in \{ 1,2,3,4,5,6 \}} x_i$
$$
\Delta q_2=\max_{x,y \in D, \left \| x-y \right \|_1=1 } \left \| q_2(x)-q_2(y) \right \|_1 \\
=|q_2(\{ 1,1,1,1,1,1 \})-q_2(\{ 6,1,1,1,1,1 \})| =5
$$
则设计拉普拉斯机制函数如下：
$$
M_{L2}(x)=q_2(x)+Lap\left ( \frac{\Delta q_2}{\epsilon} \right ) \\
= q_2(x)+Lap\left ( 50 \right )
$$


## 2 Exponential mechanism

### (a)
#### (1)
因为$q_1(x)=\frac{1}{4000} \sum_{ID=1}^{4000} Physics_{ID}$，所以全局敏感度为：
$$
\Delta q_1=\max_{x,y \in D, \left \| x-y \right \|_1=1 } \left \| q_1(x)-q_1(y) \right \|_1 \\
=\max_{p,q \in [0,100] \cap \mathbb{N}} \frac{1}{4000}|p-q| =\frac{1}{40}
$$

#### (2)
因为$q_2(x)=\max_{ID \in [1,4000]\cap \mathbb{N}} Biology_{ID}$，所以全局敏感度为：
$$
\Delta q_2=\max_{x,y \in D, \left \| x-y \right \|_1=1 } \left \| q_2(x)-q_2(y) \right \|_1 \\
=|q_2(\{ 0,0,...,0 \})-q_2(\{ 100,0,0,...,0 \})|=100
$$


### (b)
#### (1)
由$\Delta q_1 = \frac{1}{40}$，
可设计拉普拉斯机制函数如下：
$$
M_{L}(x)=q_1(x)+Lap\left ( \frac{\Delta q_1}{\epsilon} \right ) \\
= q_1(x)+Lap\left ( \frac{1}{4} \right )
$$

#### (2)
设计效用函数如下：
$$
u(x,ID)=-|q_2(x)-Biology_{ID}|
$$
由于$q_2(x) \ge Biology_{ID}$，因此$u(x,ID)=Biology_{ID}-q_2(x)$
该效用函数的意义为：衡量抽取出的生物最高分和真实的生物最高分之间的误差，误差越小，效用越高。

则
$$
\begin{align*}
\Delta u&=\max_{ID \in [1,4000]\cap \mathbb{N}}\max_{x,y \in D, \left \| x-y \right \|_1=1 } \left \| u(x,ID)-u(y,ID) \right \|_1 \\
&= |u(\{ 100,0,...,0 \}, 2)-u(\{ 100,100,...,0 \}, 2)| \\
&=100
\end{align*}
$$

可设计指数机制如下：
对于每个学生$ID$，其被抽取到的概率为：
$$
p(x, ID)=\frac{\exp(\frac{\epsilon u(x,ID)}{2 \Delta u})}{\sum_{ID=1}^{4000} \exp(\frac{\epsilon u(x,ID)}{2 \Delta u})} \\
= \frac{\exp(\frac{0.1(Biology_{ID}-q_2(x))}{200})}{\sum_{ID=1}^{4000} \exp(\frac{0.1(Biology_{ID}-q_2(x))}{200})} \\
= \frac{\exp(\frac{Biology_{ID}}{2000})}{\sum_{ID=1}^{4000} \exp(\frac{Biology_{ID}}{2000})}
$$
最后，公布被抽取到的学生的生物成绩，则该指数机制设计完毕。

## 3 Composition
### (a)
因为$q_1(x)=\frac{1}{2000} \sum_{i=1}^{2000} x_i$，所以全局敏感度为：
$$
\Delta_2 q_1=\max_{x,y \in D, \left \| x-y \right \|_1=1 } \left \| q_1(x)-q_1(y) \right \|_2 \\
=\max_{p,q \in [0,100] \cap \mathbb{N}} \frac{1}{2000}|p-q| =\frac{1}{20}
$$

假设每次所用的高斯机制的方差一致，为$\sigma^2$，满足$(\epsilon_1, \delta_1)$-DP：
由**composition theorem**可得：
为保证最终$\epsilon=1.25, \delta=10^{-5}$，应满足：
$$
100\epsilon_1=1.25, 100\delta_1=10^{-5}
$$
则解得：
$$
\epsilon_1=0.0125, \delta_1=10^{-7}
$$
则由高斯机制的隐私参数计算公式可得：
$$
\sigma=\sqrt{2 \ln(1.25/\delta_1)} \Delta_2 q_1 / \epsilon_1 \\
= \sqrt{2 \ln(1.25/10^{-7})} \frac{1}{20} / 0.0125 \\
= 4\sqrt{2 \ln(1.25 \times 10^{7})}
$$
由此
$$
\sigma^2=32 \ln(1.25 \times 10^{7}) \approx 522.9
$$


由**advanced composition theorem**：
为保证最终$\epsilon=1.25, \delta=10^{-5}$，令$\delta'=5 \times 10^{-6}$，则$(\epsilon_1, \delta_1)$应满足：
$$
\epsilon \ge \sqrt{2k \ln(1/\delta')} \epsilon_1 + k \epsilon_1 (e^{\epsilon_1} - 1) \\
\delta = \delta' + k \delta_1 
$$
带入数值得：
$$
1.25 \ge 50\epsilon_1 + 100 \epsilon_1 (e^{\epsilon_1} - 1) \ge \sqrt{200 \ln(2 \times 10^5)} \epsilon_1 + 100 \epsilon_1 (e^{\epsilon_1} - 1) \\
10^{-5} = 5 \times 10^{-6} + 100 \delta_1 
$$
可解得$\delta_1=5 \times 10^{-8}$，并得到可行的$\epsilon_1=0.02$

则由高斯机制的隐私参数计算公式可得：
$$
\sigma=\sqrt{2 \ln(1.25/\delta_1)} \Delta_2 q_1 / \epsilon_1 \\
= \sqrt{2 \ln(1.25/(5 \times 10^{-8}))} \frac{1}{20} / 0.02 \\
= 2.5\sqrt{2 \ln(2.5 \times 10^{7})}
$$
由此
$$
\sigma^2=12.5 \ln(2.5 \times 10^{7}) = 212.9
$$

### (b)
因为$q_2(x)=\max_{i \in \{ 1,2,...,2000 \}} x_i$，所以全局敏感度为：
$$
\Delta_2 q_2=\max_{x,y \in D, \left \| x-y \right \|_1=1 } \left \| q_2(x)-q_2(y) \right \|_2 \\
=\left \|q_2(\{ 0,0,...,0 \})-q_2(\{ 100,0,0,...,0 \}) \right \|_2=100
$$

由于这里的查询次数与$\epsilon, \delta$和上一问相同，因此上一小问中由composition theorem和advanced composition theorem得到的高斯机制的$\epsilon_1, \delta_1$仍然适用，此处记为$\epsilon_2, \delta_2$。

则由**composition theorem**可得：

$$
\epsilon_2=0.0125, \delta_2=10^{-7}
$$

由高斯机制的隐私参数计算公式可得：
$$
\sigma=\sqrt{2 \ln(1.25/\delta_2)} \Delta_2 q_2 / \epsilon_2 \\
= \sqrt{2 \ln(1.25/10^{-7})} 100 / 0.0125 \\
= 8000\sqrt{2 \ln(1.25 \times 10^{7})}
$$

由此
$$
\sigma^2=128000000 \ln(1.25 \times 10^{7}) \approx 2.092 \times 10^{9}
$$


由**advanced composition theorem**可得：

$$
\epsilon_2=0.02, \delta_2=5 \times 10^{-8}
$$

由高斯机制的隐私参数计算公式可得：
$$
\sigma=\sqrt{2 \ln(1.25/\delta_2)} \Delta_2 q_2 / \epsilon_2 \\
= \sqrt{2 \ln(1.25/(5 \times 10^{-8}))} 100 / 0.02 \\
= 5000\sqrt{2 \ln(2.5 \times 10^{7})}
$$
由此
$$
\sigma^2=50000000 \ln(2.5 \times 10^{7}) = 8.517 \times 10^8
$$



## 4 Randomized Response for Local DP
### (a)

由题意得：每个人都有概率$p$回答真实的答案，有概率$1-p$回答相反的答案。

对于任意回答的答案$t^\star$，当回答者性别确实为$t^\star$时，回答的$t^\star$概率为$p$，当回答者性别相反时，回答的$t^\star$概率为$1-p$。

记该随机机制为$f$。
因此，对任意两个回答者$t, t'$，概率比值$\frac{P(f(t)=t^\star)}{P(f(t')=t^\star)}$最大为$\exp (|\ln \frac{p}{1-p}|)$，则该随机机制满足local-DP，其参数为$\epsilon = |\ln \frac{p}{1-p}|$。

### (b)
Ground Truth的男性比例为$\pi$

则随机抽取到的一个人回答是男性的概率为$\pi p + (1-\pi)(1-p)$。

由$\frac{n_1}{n} = \hat{\pi} p + (1-\hat{\pi})(1-p)$可得到$\pi$的估计值为：
$$
\hat{\pi} = \frac{\frac{n_1}{n}-1+p}{2p-1}
$$

由于
$$
\begin{align*}
E[\hat{\pi}] & =E \left [\frac{\frac{n_1}{n}-1+p}{2p-1} \right ] \\
 &= \frac{\frac{E[n_1]}{n}-1+p}{2p-1} \\
 &= \frac{\frac{n (\pi p + (1-\pi)(1-p))}{n}-1+p}{2p-1} \\
 &= \frac{\pi p + (1-\pi)(1-p)-1+p}{2p-1} \\
 &= \pi
\end{align*}
$$

因此$\hat{\pi} = \frac{\frac{n_1}{n}-1+p}{2p-1}$即为$\pi$的无偏估计。

由于$n_1 \sim B(n, \pi p + (1-\pi)(1-p))$，其方差为$Var[n_1]=n (\pi p + (1-\pi)(1-p))(1 - \pi p - (1-\pi)(1-p))$，因此

计算$\hat{\pi}$的二阶矩如下：
$$
\begin{align*}
E[\hat{\pi}^2] =& E \left [ \left ( \frac{\frac{n_1}{n}-1+p}{2p-1} \right )^2 \right ] \\
=&   \frac{E[(\frac{n_1}{n})^2]-2(1-p)E[\frac{n_1}{n}]+(1-p)^2}{(2p-1)^2}   \\
=& \frac{\frac{E[n_1^2]}{n^2}-2(1-p)(\pi p + (1-\pi)(1-p))+(1-p)^2}{(2p-1)^2} \\
=& \frac{\frac{Var[n_1]+E^2[n_1]}{n^2}-2(1-p)(\pi p + (1-\pi)(1-p))+(1-p)^2}{(2p-1)^2} \\
=& \frac{\small {n (\pi p + (1-\pi)(1-p))(1 - \pi p - (1-\pi)(1-p)) + n^2 (\pi p + (1-\pi)(1-p))^2 }}{n^2(2p-1)^2} \\
&+\frac{-2(1-p)(\pi p + (1-\pi)(1-p))+(1-p)^2}{(2p-1)^2} \\
=& \frac{(\pi p + (1-\pi)(1-p))(1 - \pi p - (1-\pi)(1-p))}{n(2p-1)^2} + \\
& \frac{(1-p-\pi p - (1-\pi)(1-p))^2}{(2p-1)^2}\\
=& \pi^2 + \frac{((2p-1)\pi+1-p)(p-(2p-1)\pi)}{n(2p-1)^2}
\end{align*}
$$

因此$\hat{\pi}$的方差为：
$$
\begin{align*}
Var[\hat{\pi}] &= E[\hat{\pi}^2] - E[\hat{\pi}]^2 \\
&= \pi^2 + \frac{((2p-1)\pi+1-p)(p-(2p-1)\pi)}{n(2p-1)^2} - \pi^2 \\
&= \frac{((2p-1)\pi+1-p)(p-(2p-1)\pi)}{n(2p-1)^2}
\end{align*}
$$

## 5 Accuracy Guarantee of DP
由$\bar{x}=\frac{1}{n} \sum_{i=1}^{n} x_i$，可得$\bar{x}$的全局敏感度为：
$$
\Delta_2=\max_{x,y \in D, \left \| x-y \right \|_1=1 } \left \| \bar{x}-\bar{y} \right \|_2 \\
=  \| \{\frac{100}{n}, ..., \frac{100}{n}\}^d  \|_2 =\frac{100}{n}\sqrt{d}
$$

因此高斯机制的方差为：
$$
\sigma^2=\frac{2 \ln(1.25/\delta)}{\epsilon^2} \Delta_2^2 \\
= \frac{2 \ln(1.25/\delta)}{\epsilon^2} \frac{10000d}{n^2}
$$

记$X \sim N(0, \sigma^2)$，则对于任意$\mathcal{B}>0$，
由无穷范数等价于取绝对值最大的维度，则$\left \| M(x) - \bar{x} \right \|_\infty > \mathcal{B}$等价于误差的各维度中至少有一维的误差大于$\mathcal{B}$，则由Union Bound可得：
$$
\begin{align*}
 & P(\left \| M(x) - \bar{x} \right \|_\infty > \mathcal{B}) \\
\le & \sum_{j=1}^d P(|M(x)_j - \bar{x}_j | > \mathcal{B}) \\
= & d P(|X| > \mathcal{B})\\
\end{align*} 
$$

又由切比雪夫不等式得：
$$
P(|X| > \mathcal{B}) \le \frac{\sigma^2}{\mathcal{B}^2}
$$
（由切尔诺夫界可得：$P(|X| > \mathcal{B}) \le 2\exp(-\frac{\mathcal{B}^2}{2 \sigma^2})$）

因此：
$$
P(\left \| M(x) - \bar{x} \right \|_\infty > \mathcal{B}) \le \frac{d \sigma^2}{\mathcal{B}^2}
$$

也即
$$
P(\left \| M(x) - \bar{x} \right \|_\infty \le \mathcal{B}) \ge 1 - \frac{d \sigma^2}{\mathcal{B}^2}
$$

为使$P(\left \| M(x) - \bar{x} \right \|_\infty \le \mathcal{B}) \ge 1 - \beta$，应有$\frac{d \sigma^2}{\mathcal{B}^2} \le \beta$

则$\mathcal{B} \ge \sqrt{\frac{d \sigma^2}{\beta}}=\sqrt{\frac{d}{\beta}} \frac{\sqrt{20000d \ln(1.25/\delta)}}{\epsilon n} = \sqrt{\frac{2 \ln(1.25/\delta)}{\beta}} \frac{100d}{\epsilon n}$

由上述不等式可取$\mathcal{B} = \sqrt{\frac{2 \ln(1.25/\delta)}{\beta}} \frac{100d}{\epsilon n}$

## 6 Personalized Differential Privacy
### (a)
记两个机制分别为$M_1$和$M_2$，则对于任意两个相邻数据集$D, D'$，记它们在第j维不同
因为它们分别满足$\{ \epsilon_i^{(1)} \}_{i \in [n]}$-PDP, $\{ \epsilon_i^{(2)} \}_{i \in [n]}$-PDP：
$$
P(M_1(D) \in S_1) \le e^{\epsilon_j^{(1)}} P(M_1(D') \in S_1)\\
P(M_2(D) \in S_2) \le e^{\epsilon_j^{(2)}} P(M_2(D') \in S_2)
$$
则有：
$$
P((M_1(D),M_2(D)) \in S_1 \times S_2) \le e^{\epsilon_j^{(1)}+\epsilon_j^{(2)}} P((M_1(D'),M_2(D')) \in S_1 \times S_2)
$$

因此同时发布两机制的结果，满足$\{ \epsilon_i^{(1)}+\epsilon_i^{(2)} \}_{i \in [n]}$-PDP。

### (b)
对任意$t>0$，

记Sample Mechanism为$M_S$

由于$M(D_S)$满足$t$-DP，因此对于任意相邻数据集$D_S,D_S'$及任意输出集合$S$，都有$P(M(D_S) \in S) \le e^t P(M(D_S') \in S)$。

对于相邻的数据集$D, D'$，记它们在第$j$维不同，
由于数据集内的值不影响抽样概率，因此对任意包含同样下标的$D_S, D_S'$满足$D_S \subset D, D_S' \subset D'$，有$P(D_S'|D')=P(D_S|D)$

若$\epsilon_j \ge t$，
$$
\begin{align*}
 & \frac{P(M_S(D') \in S)}{P(M_S(D) \in S)} \\
=& \frac{\sum_{D_S' \subset D'} P(D_S'|D')P(M(D_S') \in S)}{\sum_{D_S \subset D} P(D_S|D)P(M(D_S) \in S)} \\
\le & \frac{\sum_{D_S \subset D} P(D_S|D)P(M(D_S) \in S)e^t}{\sum_{D_S \subset D} P(D_S|D)P(M(D_S) \in S)} \\
=& e^t \le e^{\epsilon_j}
\end{align*}
$$

也即$P(M_S(D') \in S) \le e^{\epsilon_j} P(M_S(D) \in S)$

若$\epsilon_j < t$，
$$
\begin{align*}
 & \frac{P(M_S(D') \in S)}{P(M_S(D) \in S)} \\
=& \frac{\sum_{D_S' \subset D'} P(D_S'|D')P(M(D_S') \in S)}{\sum_{D_S \subset D} P(D_S|D)P(M(D_S) \in S)} \\
=& \frac{\sum_{D_S' \subset D', j \in D_S'} ( P(D_S'|D')P(M(D_S') \in S) + P(D_S'/\{j\}|D')P(M(D_S'/\{j\}) \in S) )}{\sum_{D_S \subset D, j \in D_S} ( P(D_S|D)P(M(D_S) \in S) + P(D_S/\{j\}|D)P(M(D_S/\{j\}) \in S) )} \\
\le & \frac{\sum_{D_S \subset D, j \in D_S} ( P(D_S|D)P(M(D_S') \in S) + P(D_S/\{j\}|D)P(M(D_S/\{j\}) \in S) )}{\sum_{D_S \subset D, j \in D_S} ( P(D_S|D)P(M(D_S) \in S) + P(D_S/\{j\}|D)P(M(D_S/\{j\}) \in S) )} \\
=& \frac{\small{\sum_{D_S \subset D, j \in D_S}  P(D_S/\{j\}|D/\{j\}) (\frac{e^{\epsilon_j}-1}{e^t-1} P(M(D_S') \in S) + \frac{e^t-e^{\epsilon_j}}{e^t-1} P(M(D_S/\{j\}) \in S))}}
{\small{\sum_{D_S \subset D, j \in D_S}  P(D_S/\{j\}|D/\{j\}) (\frac{e^{\epsilon_j}-1}{e^t-1} P(M(D_S) \in S) + \frac{e^t-e^{\epsilon_j}}{e^t-1} P(M(D_S/\{j\}) \in S))}} \\
\end{align*}
$$

记$\lambda = \frac{e^{\epsilon_j}-1}{e^t-1}, p_1 = P(M(D_S') \in S), p_2 = P(M(D_S') \in S), p_3 = P(M(D_S/\{j\}) \in S)$
则$\frac{\lambda e^t + (1-\lambda) }{\lambda + (1-\lambda)} = e^{\epsilon_j}$
由于$M(D_S)$满足$t$-DP，且$D_S, D_S', D_S/\{j\}$两两之间距离为1，因此$|\ln (p_1-p_2)|, |\ln (p_1-p_3)|, |\ln (p_2-p_3)|$均小于$t$.

对于每一个$D_S$满足$j \in D_S$，都有
$$
\begin{align*}
& \frac{\frac{e^{\epsilon_j}-1}{e^t-1} P(M(D_S') \in S) + \frac{e^t-e^{\epsilon_j}}{e^t-1} P(M(D_S/\{j\}) \in S)}
{\frac{e^{\epsilon_j}-1}{e^t-1} P(M(D_S) \in S) + \frac{e^t-e^{\epsilon_j}}{e^t-1} P(M(D_S/\{j\}) \in S)} \\
=& \frac{\lambda p_1 + (1-\lambda) p_3}{\lambda p_2 + (1-\lambda) p_3} \\
=& \frac{\lambda \frac{p_1}{p_3} + (1-\lambda) }{\lambda \frac{p_2}{p_3} + (1-\lambda)}
\end{align*}
$$

则若$p_2 \le p_3$，
$$
\begin{align*}
& \frac{\frac{e^{\epsilon_j}-1}{e^t-1} P(M(D_S') \in S) + \frac{e^t-e^{\epsilon_j}}{e^t-1} P(M(D_S/\{j\}) \in S)}
{\frac{e^{\epsilon_j}-1}{e^t-1} P(M(D_S) \in S) + \frac{e^t-e^{\epsilon_j}}{e^t-1} P(M(D_S/\{j\}) \in S)} \\
=& \frac{\lambda \frac{p_1}{p_3} + (1-\lambda) }{\lambda \frac{p_2}{p_3} + (1-\lambda)} \\
\le & \frac{\lambda \frac{p_2}{p_3} e^t + (1-\lambda) }{\lambda \frac{p_2}{p_3} + (1-\lambda)}\\
\le & \frac{\lambda e^t + (1-\lambda) }{\lambda + (1-\lambda)} \\
= & e^{\epsilon_j}
\end{align*}
$$

若$p_2 > p_3$，
$$
\begin{align*}
& \frac{\frac{e^{\epsilon_j}-1}{e^t-1} P(M(D_S') \in S) + \frac{e^t-e^{\epsilon_j}}{e^t-1} P(M(D_S/\{j\}) \in S)}
{\frac{e^{\epsilon_j}-1}{e^t-1} P(M(D_S) \in S) + \frac{e^t-e^{\epsilon_j}}{e^t-1} P(M(D_S/\{j\}) \in S)} \\
=& \frac{\lambda \frac{p_1}{p_3} + (1-\lambda) }{\lambda \frac{p_2}{p_3} + (1-\lambda)} \\
\le & \frac{\lambda e^t + (1-\lambda) }{\lambda \frac{p_2}{p_3} + (1-\lambda)}\\
\le & \frac{\lambda e^t + (1-\lambda) }{\lambda + (1-\lambda)} \\
= & e^{\epsilon_j}
\end{align*}
$$

综上所述，
$$
\frac{\frac{e^{\epsilon_j}-1}{e^t-1} P(M(D_S') \in S) + \frac{e^t-e^{\epsilon_j}}{e^t-1} P(M(D_S/\{j\}) \in S)}
{\frac{e^{\epsilon_j}-1}{e^t-1} P(M(D_S) \in S) + \frac{e^t-e^{\epsilon_j}}{e^t-1} P(M(D_S/\{j\}) \in S)} \le e^{\epsilon_j}
$$

因此
$$
\begin{align*}
 & \frac{P(M_S(D') \in S)}{P(M_S(D) \in S)} \\
=& \frac{\small{\sum_{D_S \subset D, j \in D_S}  P(D_S/\{j\}|D/\{j\}) (\frac{e^{\epsilon_j}-1}{e^t-1} P(M(D_S') \in S) + \frac{e^t-e^{\epsilon_j}}{e^t-1} P(M(D_S/\{j\}) \in S))}}
{\small{\sum_{D_S \subset D, j \in D_S}  P(D_S/\{j\}|D/\{j\}) (\frac{e^{\epsilon_j}-1}{e^t-1} P(M(D_S) \in S) + \frac{e^t-e^{\epsilon_j}}{e^t-1} P(M(D_S/\{j\}) \in S))}} \\
\le & e^{\epsilon_j}
\end{align*}
$$



综上所述，对任意$j$，都有
$$
\frac{P(M_S(D') \in S)}{P(M_S(D) \in S)} \le e^{\epsilon_j}
$$

则$M_S$满足$\{ \epsilon_i \}_{i \in [n]}$-PDP。